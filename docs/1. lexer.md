# The Lexer

The goal of the lexer is to take the source code and identify tokens.

## Identify Tokens

Example code we will tokenize:

```javascript
// variables
let five = 5;
let ten = 10;

// functions
let add = fn(x, y) {
	x + y;
};

// setting function output to a variable
let result = add(five, ten);
```

```nix
# variables
five = 5
ten = 10

# functions
add = x: y: x + y

# setting function output to a variable
result five ten
```

```powershell
# psd files do not allow for invoking functions, it just contains data
# PSD1, tokens can have quotes and not have quotes
@{
	five = 5;
	ten = 10;
}
```

### Breaking down the problem

In the 1st example, we have numbers:
- 5
- 10

Variable Names
- x
- y
- add
- result

Other words
- let
- function

Special Characters
- (, ), {, }, =, ;.

### Approach ... Categories

Numbers are just integers so we can treat them as such.  They can have a seperate type.

We don't care if it is 5 or a 10... only that it is a number.

Variable names we will call identifiers.

`let` and `function` are key words used during the parsing phase.

Special Characters are the last category.

### Token data structure.